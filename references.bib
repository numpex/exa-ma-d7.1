
@inproceedings{balay_efficient_1997,
	title = {Efficient Management of Parallelism in Object Oriented Numerical Software Libraries},
	pages = {163--202},
	booktitle = {Modern Software Tools in Scientific Computing},
	publisher = {BirkhÃ¤user Press},
	author = {Balay, Satish and Gropp, William D. and {McInnes}, Lois Curfman and Smith, Barry F.},
	editor = {Arge, E. and Bruaset, A. M. and Langtangen, H. P.},
	date = {1997},
}

@article{zhang_petscsf_2022,
	title = {The {PetscSF} Scalable Communication Layer},
	volume = {33},
	pages = {842--853},
	number = {4},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	author = {Zhang, Junchao and Brown, Jed and Balay, Satish and Faibussowitsch, Jacob and Knepley, Matthew and Marin, Oana and Mills, Richard Tran and Munson, Todd and Smith, Barry F. and Zampini, Stefano},
	date = {2022},
}

@article{dalcin_parallel_2011,
	title = {Parallel distributed computing using Python},
	volume = {34},
	issn = {0309-1708},
	doi = {10.1016/j.advwatres.2011.04.013},
	pages = {1124 -- 1139},
	number = {9},
	journaltitle = {Advances in Water Resources},
	author = {Dalcin, Lisandro D. and Paz, Rodrigo R. and Kler, Pablo A. and Cosimo, Alejandro},
	date = {2011},
}

@report{balay_petsctao_2024,
	title = {{PETSc}/{TAO} Users Manual},
	number = {{ANL}-21/39 - Revision 3.21},
	institution = {Argonne National Laboratory},
	author = {Balay, Satish and Abhyankar, Shrirang and Adams, Mark F. and Benson, Steven and Brown, Jed and Brune, Peter and Buschelman, Kris and Constantinescu, Emil and Dalcin, Lisandro and Dener, Alp and Eijkhout, Victor and Faibussowitsch, Jacob and Gropp, William D. and Hapla, VÃ¡clav and Isaac, Tobin and Jolivet, Pierre and Karpeev, Dmitry and Kaushik, Dinesh and Knepley, Matthew G. and Kong, Fande and Kruger, Scott and May, Dave A. and {McInnes}, Lois Curfman and Mills, Richard Tran and Mitchell, Lawrence and Munson, Todd and Roman, Jose E. and Rupp, Karl and Sanan, Patrick and Sarich, Jason and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Hong and Zhang, Junchao},
	date = {2024},
	doi = {10.2172/2205494},
}

@misc{balay_petsc_2024,
	title = {{PETSc} Web page},
	url = {https://petsc.org/},
	author = {Balay, Satish and Abhyankar, Shrirang and Adams, Mark F. and Benson, Steven and Brown, Jed and Brune, Peter and Buschelman, Kris and Constantinescu, Emil M. and Dalcin, Lisandro and Dener, Alp and Eijkhout, Victor and Faibussowitsch, Jacob and Gropp, William D. and Hapla, VÃ¡clav and Isaac, Tobin and Jolivet, Pierre and Karpeev, Dmitry and Kaushik, Dinesh and Knepley, Matthew G. and Kong, Fande and Kruger, Scott and May, Dave A. and {McInnes}, Lois Curfman and Mills, Richard Tran and Mitchell, Lawrence and Munson, Todd and Roman, Jose E. and Rupp, Karl and Sanan, Patrick and Sarich, Jason and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Hong and Zhang, Junchao},
	date = {2024},
}

@software{prudhomme_feelppfeelpp_2024,
	title = {feelpp/feelpp: Feel++ Release V111 preview.10},
	rights = {Creative Commons Attribution 4.0 International, {GNU} Lesser General Public License v3.0 or later, {GNU} General Public License v3.0 or later},
	url = {https://zenodo.org/doi/10.5281/zenodo.591797},
	shorttitle = {feelpp/feelpp},
	abstract = {ðŸŽ‰ We're happy to share our developments as we approach the V111 release of Feel++. Following a refreshed naming strategy, we've moved to the -preview.x suffix from the conventional -alpha.x, -beta, or -rc labels. This change signifies our dedication to enhancing transparency and setting clear expectations for our pre-release versions.

Each pre-release version of Feel++ undergoes a rigorous process, encompassing detailed reviews, extensive tests across varied scenarios, and careful packaging. Our commitment to delivering a high-quality, reliable experience is reflected in our comprehensive platform support strategy. Alongside offering support for the latest two Long-Term Support ({LTS}) versions of Ubuntu and the newest {LTS} version of Debian, we're excited to announce that Feel++ is now accessible to Windows users through the Windows Subsystem for Linux ({WSL}) and to Mac users via {MacPorts}, Homebrew, Docker and now Apptainer. This expansion of platform support is a testament to our commitment to making Feel++ as accessible and versatile as possible for our diverse user base.

As we continue to refine and enhance Feel++, the V111 release promises to bring forward significant innovations and improvements. Stay tuned for further updates of Feel++.

Packages



ðŸ“¦ Ubuntu packages

ðŸ“¦ Debian packages

ðŸ“¦ Docker images


docker pull ghcr.io/feelpp/feelpp:v0.111.0-preview.10-jammy
docker run ghcr.io/feelpp/feelpp:v0.111.0-preview.10-jammy ls




ðŸ“¦ Apptainer images


apptainer pull -F oras://ghcr.io/feelpp/feelpp:v0.111.0-preview.10-jammy-sif
apptainer exec feelpp\_v0.111.0-preview.10-jammy-sif.sif feelpp\_toolbox\_fluid --version


What's Changed

Exciting New Features ðŸŽ‰



resolve 2231 : Support parts configuration in exporter by @vincentchabannes in https://github.com/feelpp/feelpp/pull/2232

resolves 1489 and 2175: enrich range object and simplify {FunctionSpace} by @prudhomm in https://github.com/feelpp/feelpp/pull/2176

resolves 2191 and 2196: cleanup and python wrapper for forms and implement feelpp namespace package by @prudhomm in https://github.com/feelpp/feelpp/pull/2227

resolves 2233: improve hdg toolbox, add new terms by @prudhomm in https://github.com/feelpp/feelpp/pull/2236

resolves 2259: add script to get feelpp version and improve packaging workflow by @prudhomm in https://github.com/feelpp/feelpp/pull/2260


{HPC} Changes



resolves 2246: fix non blocking mpi communication for large scale communications by @vincentchabannes in https://github.com/feelpp/feelpp/pull/2249


Recent Publications using Feel++



Ktirio Urban Building: A Computational Framework for City Energy Simulations Enhanced by {CI}/{CD} Innovations on {EuroHPC} Systems

Nonlinear compressive reduced basis approximation for multi-parameter elliptic problem

2D Axisymmetric Modeling of the {HTS} Insert Nougat in a Background Magnetic Field Generated by Resistive Magnet


Enjoy!

Full Changelog: https://github.com/feelpp/feelpp/compare/v0.111.0-preview.9...v0.111.0-preview.10},
	version = {v0.111.0-preview.10},
	publisher = {[object Object]},
	author = {Prud'homme, Christophe and Chabannes, Vincent and Saigre, Thomas and Trophime, Christophe and Berti, Luca and SamakÃ©, Abdoulaye and Van Landeghem, CÃ©line and Szopos, Marcela and Giraldi, Laetitia and Bertoluzza, Silvia and Maday, Yvon},
	urldate = {2024-09-04},
	date = {2024-07-15},
	doi = {10.5281/ZENODO.591797},
}

@misc{ootomo_dgemm_2024,
	title = {{DGEMM} on Integer Matrix Multiplication Unit},
	url = {http://arxiv.org/abs/2306.11975},
	abstract = {Deep learning hardware achieves high throughput and low power consumption by reducing computing precision and specializing in matrix multiplication. For machine learning inference, fixed-point value computation is commonplace, where the input and output values and the model parameters are quantized. Thus, many processors are now equipped with fast integer matrix multiplication units ({IMMU}). It is of significant interest to find a way to harness these {IMMUs} to improve the performance of {HPC} applications while maintaining accuracy. We focus on the Ozaki scheme, which computes a high-precision matrix multiplication by using lower-precision computing units, and show the advantages and disadvantages of using {IMMU}. The experiment using integer Tensor Cores shows that we can compute double-precision matrix multiplication faster than {cuBLAS} and an existing Ozaki scheme implementation on {FP}16 Tensor Cores on {NVIDIA} consumer {GPUs}. Furthermore, we demonstrate accelerating a quantum circuit simulation by up to 4.33 while maintaining the {FP}64 accuracy.},
	number = {{arXiv}:2306.11975},
	publisher = {{arXiv}},
	author = {Ootomo, Hiroyuki and Ozaki, Katsuhisa and Yokota, Rio},
	urldate = {2024-06-28},
	date = {2024-03-30},
	eprinttype = {arxiv},
	eprint = {2306.11975 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
}

@inproceedings{haidar_harnessing_2018,
	location = {Dallas, {TX}, {USA}},
	title = {Harnessing {GPU} Tensor Cores for Fast {FP}16 Arithmetic to Speed up Mixed-Precision Iterative Refinement Solvers},
	isbn = {978-1-5386-8384-2},
	url = {https://ieeexplore.ieee.org/document/8665777/},
	doi = {10.1109/SC.2018.00050},
	eventtitle = {{SC}18: International Conference for High Performance Computing, Networking, Storage and Analysis},
	pages = {603--613},
	booktitle = {{SC}18: International Conference for High Performance Computing, Networking, Storage and Analysis},
	publisher = {{IEEE}},
	author = {Haidar, Azzam and Tomov, Stanimire and Dongarra, Jack and Higham, Nicholas J.},
	urldate = {2024-06-28},
	date = {2018-11},
}
