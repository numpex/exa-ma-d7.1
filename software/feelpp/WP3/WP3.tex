%!TEX root = ../../../exa-ma-d7.1.tex
\section{Software: \texorpdfstring{\Feelpp}{Feel++}}
\label{sec:WP3:Feelpp:software}

\begin{table}[!ht]
    \centering
    { \setlength{\parindent}{0pt}
    \def\arraystretch{1.25}
    \arrayrulecolor{numpexgray}
    {\fontsize{9}{11}\selectfont
    \begin{tabular}{!{\color{numpexgray}\vrule}p{.4\textwidth}!{\color{numpexgray}\vrule}p{.6\textwidth}!{\color{numpexgray}\vrule}}
        \rowcolor{numpexgray}{\rule{0pt}{2.5ex}\color{white}\bf Field} & {\rule{0pt}{2.5ex}\color{white}\bf Details} \\
        \rowcolor{white}\textbf{Consortium} & \begin{tabular}{l}
\Feelpp Consortium\\
\end{tabular} \\
        \rowcolor{numpexlightergray}\textbf{Exa-MA Partners} & \begin{tabular}{l}
CNRS\\
Inria Grenoble\\
Unistra\\
\end{tabular} \\
        \rowcolor{white}\textbf{Contact Emails} & \begin{tabular}{l}
christophe.prudhomme@cemosis.fr\\
vincent.chabannes@cemosis.fr\\
\end{tabular} \\
        \rowcolor{numpexlightergray}\textbf{Supported Architectures} & \begin{tabular}{l}
CPU Only\\
\end{tabular} \\
        \rowcolor{white}\textbf{Repository} & \href{https://github.com/feelpp/feelpp}{https://github.com/feelpp/feelpp} \\
        \rowcolor{numpexlightergray}\textbf{License} & \begin{tabular}{l}
OSS:: GPL v*\\
OSS:: LGPL v*\\
\end{tabular} \\
        \rowcolor{white}\textbf{Bottlenecks roadmap} & \begin{tabular}{l}
B10 - Scientific Productivity\\
B11 - Reproducibility and Replicability of Computation\\
B12 - Pre/Post Processing and In-Situ Processing\\
B2 - Interconnect Technology\\
B6 - Data Management\\
B7 - Exascale Algorithms\\
\end{tabular} \\
\rowcolor{numpexlightergray}\textbf{Contributors} & \begin{tabular}{l}
    Christophe Prud'homme (UNISTRA)\\
    Vincent Chabannes (UNISTRA)\\
    Thomas Saigre (UNISTRA)\\
\end{tabular}\\
        \hline
    \end{tabular}
    }}
    \caption{WP3: \Feelpp Information}
\end{table}

\subsection{Software Overview}
\label{sec:WP3:Feelpp:summary}

In~\cref{tab:WP3:Feelpp:features} we provide the summary of the \Feelpp features relevant to the work package which are briefly discussed.

\begin{table}[!ht]
    \centering
    {
        \setlength{\parindent}{0pt}
        \def\arraystretch{1.25}
        \arrayrulecolor{numpexgray}
        {
            \fontsize{9}{11}\selectfont
            \begin{tabular}{!{\color{numpexgray}\vrule}p{.25\linewidth}!{\color{numpexgray}\vrule}p{.6885\linewidth}!{\color{numpexgray}\vrule}}

    \rowcolor{numpexgray}{\rule{0pt}{2.5ex}\color{white}\bf Features} &  {\rule{0pt}{2.5ex}\color{white}\bf Short Description }\\

\rowcolor{white}    algebraic multiphysics coupling & In \Feelpp, algebraic multiphysics coupling is achieved through the fieldsplit PETSc preconditioner. This allows the construction of block preconditioners, leveraging both PETScâ€™s built-in preconditioners and in-house preconditioners designed for specific applications, such as computational fluid dynamics (CFD) and magnetostatic problems. These preconditioners enhance the solver's performance for coupled systems by efficiently handling the interaction between different physical fields. \\
\rowcolor{numpexlightergray}    domain decomposition methods & \Feelpp provides support for domain decomposition methods, such as hp-mortar methods. These methods utilize specialized preconditioners that exploit the structure of mortar elements to improve solver efficiency. The hp-mortar approach allows for flexible discretization and is particularly useful for non-conforming meshes and multi-domain problems, enhancing both scalability and accuracy in large-scale simulations. \\
\hline
\end{tabular}
        }
    }
    \caption{WP3: \Feelpp Features}
    \label{tab:WP3:Feelpp:features}
\end{table}


\subsection{Parallel Capabilities}
\label{sec:WP3:Feelpp:performances}

\begin{description}
    \item[Parallel Environment:] MPI.
    \item[Architectures] CPU Only: Gaya~\cref{sec:arch:gaya} and almost all JU systems~\cref{sec:arch:eurohpc-ju} except Marenostrum 5 and Deucalion.
    \item[Scalability] Only Speedups are measured
\end{description}

\subsection{Initial Performance Metrics}
\label{sec:WP3:Feelpp:metrics}

This section provides a summary of initial performance benchmarks performed in the context of WP3. It ensures reproducibility by detailing input/output datasets, benchmarking tools, and the results. All data should be publicly available, ideally with a DOI for future reference.

\begin{itemize}
    \item \textbf{Overall Performance:} Summarize the software's computational performance, energy efficiency, and scalability results across different architectures (e.g., CPU, GPU, hybrid systems).
    \item \textbf{Input/Output Dataset:} Provide a detailed description of the dataset used for the benchmark, including:
        \begin{itemize}
            \item Input dataset size, structure, and format (e.g., CSV, HDF5, NetCDF).
            \item Output dataset format and key results.
            \item Location of the dataset (e.g., GitHub repository, institutional repository, or open access platform).
            \item DOI or permanent link for accessing the dataset.
        \end{itemize}
    \item \textbf{open-data Access:} Indicate whether the datasets used for the benchmark are open access, and provide a DOI or a direct link for download. Where applicable, highlight any licensing constraints.
    \item \textbf{Challenges:} Identify any significant bottlenecks or challenges observed during the benchmarking process, including data handling and computational performance.
    \item \textbf{Future Improvements:} Outline areas for optimization, including dataset handling, memory usage, or algorithmic efficiency, to address identified challenges.
\end{itemize}

\subsubsection{Benchmark \#1: Laplacian and Linear Elasticity}
\paragraph{Description:} Briefly describe the benchmark case, including the problem size, target architecture (e.g., CPU, GPU), and the input data. Mention the specific goals of the benchmark (e.g., testing scalability, energy efficiency).

\paragraph{Benchmarking Tools Used:} List the tools used for performance analysis, such as Extrae, Score-P, TAU, Vampir, or Nsight, and specify what metrics were measured (e.g., execution time, FLOPS, energy consumption).

\paragraph{Input/Output Dataset Description:}
\paragraph{Input Data:} Describe the input dataset (size, format, data type) and provide a DOI or link to access it.

\paragraph{Output Data:} Specify the structure of the results (e.g., memory usage, runtime logs) and how they can be accessed or replicated.

\paragraph{Data Repository:} Indicate where the data is stored (e.g., Zenodo, institutional repository) and provide a DOI or URL for accessing the data.

\paragraph{Results Summary:} Include a summary of key metrics (execution time, memory usage, FLOPS) and their comparison across architectures (e.g., CPU, GPU).

\paragraph{Challenges Identified:} Describe any bottlenecks encountered (e.g., memory usage, parallelization inefficiencies) and how they impacted the benchmark.

\subsubsection{Benchmark \#2: Heat flows and temperature surfaces}

\fullcite{noauthor_iso_2017}
\paragraph{Description:} Briefly describe the benchmark case, including the problem size, target architecture (e.g., CPU, GPU), and the input data. Mention the specific goals of the benchmark (e.g., testing scalability, energy efficiency).

\paragraph{Benchmarking Tools Used:} List the tools used for performance analysis, such as Extrae, Score-P, TAU, Vampir, or Nsight, and specify what metrics were measured (e.g., execution time, FLOPS, energy consumption).

\paragraph{Input/Output Dataset Description:}
\paragraph{Input Data:} Describe the input dataset (size, format, data type) and provide a DOI or link to access it.

\paragraph{Output Data:} Specify the structure of the results (e.g., memory usage, runtime logs) and how they can be accessed or replicated.

\paragraph{Data Repository:} Indicate where the data is stored (e.g., Zenodo, institutional repository) and provide a DOI or URL for accessing the data.

\paragraph{Results Summary:} Include a summary of key metrics (execution time, memory usage, FLOPS) and their comparison across architectures (e.g., CPU, GPU).

\paragraph{Challenges Identified:} Describe any bottlenecks encountered (e.g., memory usage, parallelization inefficiencies) and how they impacted the benchmark.

\subsubsection{Benchmark \#3: CFD FDA Benchmark}

\fullcite{chabannes_high_2017}
\paragraph{Description:} Briefly describe the benchmark case, including the problem size, target architecture (e.g., CPU, GPU), and the input data. Mention the specific goals of the benchmark (e.g., testing scalability, energy efficiency).

\paragraph{Benchmarking Tools Used:} List the tools used for performance analysis, such as Extrae, Score-P, TAU, Vampir, or Nsight, and specify what metrics were measured (e.g., execution time, FLOPS, energy consumption).

\paragraph{Input/Output Dataset Description:}
\paragraph{Input Data:} Describe the input dataset (size, format, data type) and provide a DOI or link to access it.

\paragraph{Output Data:} Specify the structure of the results (e.g., memory usage, runtime logs) and how they can be accessed or replicated.

\paragraph{Data Repository:} Indicate where the data is stored (e.g., Zenodo, institutional repository) and provide a DOI or URL for accessing the data.

\paragraph{Results Summary:} Include a summary of key metrics (execution time, memory usage, FLOPS) and their comparison across architectures (e.g., CPU, GPU).

\paragraph{Challenges Identified:} Describe any bottlenecks encountered (e.g., memory usage, parallelization inefficiencies) and how they impacted the benchmark.

\subsubsection{Benchmark \#4: Conjuguate heat transfer}

\fullcite{saigre_coupled_2024}
\paragraph{Description:} Briefly describe the benchmark case, including the problem size, target architecture (e.g., CPU, GPU), and the input data. Mention the specific goals of the benchmark (e.g., testing scalability, energy efficiency).

\paragraph{Benchmarking Tools Used:} List the tools used for performance analysis, such as Extrae, Score-P, TAU, Vampir, or Nsight, and specify what metrics were measured (e.g., execution time, FLOPS, energy consumption).

\paragraph{Input/Output Dataset Description:}
\paragraph{Input Data:} Describe the input dataset (size, format, data type) and provide a DOI or link to access it.

\paragraph{Output Data:} Specify the structure of the results (e.g., memory usage, runtime logs) and how they can be accessed or replicated.

\paragraph{Data Repository:} Indicate where the data is stored (e.g., Zenodo, institutional repository) and provide a DOI or URL for accessing the data.

\paragraph{Results Summary:} Include a summary of key metrics (execution time, memory usage, FLOPS) and their comparison across architectures (e.g., CPU, GPU).

\paragraph{Challenges Identified:} Describe any bottlenecks encountered (e.g., memory usage, parallelization inefficiencies) and how they impacted the benchmark.

\subsection{12-Month Roadmap}
\label{sec:WP3:Feelpp:roadmap}

In this section, describe the roadmap for improving benchmarks and addressing the challenges identified. This should include:
\begin{itemize}
    \item \textbf{Data Improvements:} Plans for improving input/output data management, including making datasets more accessible and ensuring reproducibility through open-data initiatives.
    \item \textbf{Methodology Application:} Implementation of the benchmarking methodology proposed in this deliverable to streamline reproducibility and dataset management.
    \item \textbf{Results Retention:} Plans to maintain benchmark results in a publicly accessible repository with appropriate metadata and documentation, ensuring long-term usability.
\end{itemize}

In~\cref{tab:WP3:Feelpp:bottlenecks}, we briefly discuss the bottleneck roadmap associated to the software and relevant to the work package.

\begin{table}[!ht]
    \centering



    \centering
    {
        \setlength{\parindent}{0pt}
        \def\arraystretch{1.25}
        \arrayrulecolor{numpexgray}
        {
            \fontsize{9}{11}\selectfont
            \begin{tabular}{!{\color{numpexgray}\vrule}p{.25\linewidth}!{\color{numpexgray}\vrule}p{.6885\linewidth}!{\color{numpexgray}\vrule}}

    \rowcolor{numpexgray}{\rule{0pt}{2.5ex}\color{white}\bf Bottlenecks} &  {\rule{0pt}{2.5ex}\color{white}\bf Short Description }\\

\rowcolor{white}    B10 - Scientific Productivity & provide short description here \\
\rowcolor{numpexlightergray}    B11 - Reproducibility and Replicability of Computation & provide short description here \\
\rowcolor{white}    B12 - Pre/Post Processing and In-Situ Processing & provide short description here \\
\rowcolor{numpexlightergray}    B2 - Interconnect Technology & provide short description here \\
\rowcolor{white}    B6 - Data Management & provide short description here \\
\rowcolor{numpexlightergray}    B7 - Exascale Algorithms & enable hpddm and better preconditionner configurations at large scale (eg. algebraic multigrid), enable algebraic saddle point preconditioners from WP3, enable hp-mortar and compression strategies; update with latest PETSc improvement and start using PETSc GPU API\\
\hline
\end{tabular}
        }
    }
    \caption{WP3: \Feelpp plan with Respect to Relevant Bottlenecks}
    \label{tab:WP3:Feelpp:bottlenecks}
\end{table}