\section{Software: Scimba}
\label{sec:WP2:Scimba:software}

\begin{table}[h!]
    \centering
    { \setlength{\parindent}{0pt}
        \def\arraystretch{1.25}
        \arrayrulecolor{numpexgray}
        {\fontsize{9}{11}\selectfont

            \begin{tabular}{!{\color{numpexgray}\vrule}p{.4\textwidth}!{\color{numpexgray}\vrule}p{.6\textwidth}!{\color{numpexgray}\vrule}}
                \rowcolor{numpexgray}{\rule{0pt}{2.5ex}\color{white}\bf Field}
                 & {\rule{0pt}{2.5ex}\color{white}\bf Details}                                         \\
                \rowcolor{white}\textbf{Consortium}
                 & \begin{tabular}{l}
                       INRIA   \\
                       UNISTRA \\
                   \end{tabular}                                                                   \\
                \rowcolor{numpexlightergray}\textbf{Exa-MA Partners}
                 & \begin{tabular}{l}
                       Unistra \\
                   \end{tabular}                                                                   \\
                \rowcolor{white}\textbf{Contact Emails}
                 & \begin{tabular}{l}
                       emmanuel.franck@inria.fr      \\
                       victor.michel-dansac@inria.fr \\
                   \end{tabular}                                                       \\
                \rowcolor{numpexlightergray}\textbf{Supported Architectures}
                 & \begin{tabular}{l}
                       CPU or GPU \\
                   \end{tabular}                                                                   \\
                \rowcolor{white}\textbf{Repository}
                 & \href{https://gitlab.inria.fr/scimba/scimba}{https://gitlab.inria.fr/scimba/scimba} \\
                \rowcolor{numpexlightergray}\textbf{License}
                 & \begin{tabular}{l}
                       MIT \\
                   \end{tabular}                                                                   \\
                \rowcolor{white}\textbf{Bottlenecks roadmap}
                 & \begin{tabular}{l}
                       B10 - Scientific Productivity                          \\
                       B11 - Reproducibility and Replicability of Computation \\
                       B6 - Data Management                                   \\
                       B7 - Exascale Algorithms                               \\
                   \end{tabular}                              \\
                \bottomrule
            \end{tabular}
        }}
    \caption{WP2: Scimba Information}
\end{table}

\subsection{Software Overview}
\label{sec:WP2:Scimba:summary}

In~\cref{tab:WP2:Scimba:features} we provide a summary of the software features relevant to the work package which are briefly discussed.

\begin{table}[h!]
    \centering
    {
        \setlength{\parindent}{0pt}
        \def\arraystretch{1.25}
        \arrayrulecolor{numpexgray}
        {
            \fontsize{9}{11}\selectfont
            \begin{tabular}{!{\color{numpexgray}\vrule}p{.25\linewidth}!{\color{numpexgray}\vrule}p{.6885\linewidth}!{\color{numpexgray}\vrule}}
                \rowcolor{numpexgray}{\rule{0pt}{2.5ex}\color{white}\bf Features}
                 & {\rule{0pt}{2.5ex}\color{white}\bf Short Description } \\
                \rowcolor{white}    PINNs
                 & PINNs: Physics-Informed Neural Networks                \\
                \rowcolor{numpexlightergray}    PINOs
                 & PINOs: Physics-Informed Neural Operators               \\
                \rowcolor{white}    Neural Galerkin
                 & implementation of the Neural Galerkin method           \\
                \rowcolor{numpexlightergray} ML architectures
                 & implementation of machine learning architectures
                (MLPs, PointNets, \dots)                                  \\
                \rowcolor{white} classical methods
                 & started implementing a fully differentiable
                DG method on multi-dimensional Cartesian meshes           \\
            \end{tabular}
        }
    }
    \caption{WP2: Scimba Features}
    \label{tab:WP2:Scimba:features}
\end{table}


\subsection{Parallel Capabilities}
\label{sec:WP2:Scimba:performances}

\begin{itemize}
    \item Parallel programming environment:
          automatic parallelization tools called within \texttt{PyTorch}
          (e.g. GPU parallelization with CUDA or shared-memory parallelization with OpenMP)
    \item Parallel computation environment: computing servers of IRMA (Unistra),
          with a GPU (AMD Instinct MI210) or several CPU nodes (AMD EPYC 7713).
    \item This software is designed to be used on a single node at the moment.
          Parallelization on multiple nodes is in the roadmap.
    \item \textbf{Scalability:}
          In theory, the software can be scaled to multiple nodes, but this has not been tested yet.
    \item \textbf{Integration with Other Systems:}
          Integration with Feel++ is underway:
          solution data produced with Feel++ has successfully been
          used to train neural networks in Scimba.
\end{itemize}


% \subsection{Initial Performance Metrics}
% \label{sec:WP2:Scimba:metrics}

% This section provides a summary of initial performance benchmarks performed in the context of WP2. It ensures reproducibility by detailing input/output datasets, benchmarking tools, and the results. All data should be publicly available, ideally with a DOI for future reference.

% \begin{itemize}
%     \item \textbf{Overall Performance:} Summarize the software's computational performance, energy efficiency, and scalability results across different architectures (e.g., CPU, GPU, hybrid systems).
%     \item \textbf{Input/Output Dataset:} Provide a detailed description of the dataset used for the benchmark, including:
%           \begin{itemize}
%               \item Input dataset size, structure, and format (e.g., CSV, HDF5, NetCDF).
%               \item Output dataset format and key results.
%               \item Location of the dataset (e.g., GitHub repository, institutional repository, or open access platform).
%               \item DOI or permanent link for accessing the dataset.
%           \end{itemize}
%     \item \textbf{open-data Access:} Indicate whether the datasets used for the benchmark are open access, and provide a DOI or a direct link for download. Where applicable, highlight any licensing constraints.
%     \item \textbf{Challenges:} Identify any significant bottlenecks or challenges observed during the benchmarking process, including data handling and computational performance.
%     \item \textbf{Future Improvements:} Outline areas for optimization, including dataset handling, memory usage, or algorithmic efficiency, to address identified challenges.
% \end{itemize}

% \subsubsection{Benchmark \#1}
% \begin{itemize}
%     \item \textbf{Description:} Briefly describe the benchmark case, including the problem size, target architecture (e.g., CPU, GPU), and the input data. Mention the specific goals of the benchmark (e.g., testing scalability, energy efficiency).
%     \item \textbf{Benchmarking Tools Used:} List the tools used for performance analysis, such as Extrae, Score-P, TAU, Vampir, or Nsight, and specify what metrics were measured (e.g., execution time, FLOPS, energy consumption).
%     \item \textbf{Input/Output Dataset Description:}
%           \begin{itemize}
%               \item \textbf{Input Data:} Describe the input dataset (size, format, data type) and provide a DOI or link to access it.
%               \item \textbf{Output Data:} Specify the structure of the results (e.g., memory usage, runtime logs) and how they can be accessed or replicated.
%               \item \textbf{Data Repository:} Indicate where the data is stored (e.g., Zenodo, institutional repository) and provide a DOI or URL for accessing the data.
%           \end{itemize}
%     \item \textbf{Results Summary:} Include a summary of key metrics (execution time, memory usage, FLOPS) and their comparison across architectures (e.g., CPU, GPU).
%     \item \textbf{Challenges Identified:} Describe any bottlenecks encountered (e.g., memory usage, parallelization inefficiencies) and how they impacted the benchmark.
% \end{itemize}

\subsection{12-Month Roadmap}
\label{sec:WP2:Scimba:roadmap}

In this section, describe the roadmap for improving benchmarks and addressing the challenges identified. This should include:
\begin{itemize}
    \item \textbf{Data Improvements:} As a physics-informed machine learning framework, input data of Scimba will consist in small \texttt{json} (or \texttt{yaml}, etc.) files containing the parameters of the PDEs to solve and the neural networks solving them. Output files, in \texttt{PyTorch}'s \texttt{.pth} format, contain the trained neural networks; figures showing approximate solutions are produced. At the moment, no input data management is available, but it is planned to be implemented in the next 12 months. Output data is created and locally saved, but not clearly managed at the moment.
    \item \textbf{Methodology Application:} No clear benchmark is available at the moment, but the software is being tested on a variety of problems, from simple ODEs to more complex PDEs. At the moment, around 50 examples are available, but without clear benchmarking. The roadmap includes the implementation of a benchmark suite, with a variety of problems and datasets, to test the software's performance and scalability.
    \item \textbf{Results Retention:} The roadmap includes the implementation of a data management system, with versioning and metadata, to ensure reproducibility and long-term usability. Since the code is available on GitHub, versioning is ensured to replicate the results.
    \item \textbf{Performance Results:} At the moment, the framework is parallelized on CPUs (shared-memory) and single GPU nodes, thanks to \texttt{PyTorch}'s intrinsic parallelization capabilities.
          The roadmap includes multi-GPU support and performance optimization.
          Namely, we will measure performance (using e.g. elapsed time) and mathematical accuracy (using e.g. the $L^2$ error between the approximate solution and a reference one).
\end{itemize}

In~\cref{tab:WP2:Scimba:bottlenecks}, we briefly discuss the bottleneck roadmap associated to the software and relevant to the work package.

\begin{table}[h!]
    \centering
    {
        \setlength{\parindent}{0pt}
        \def\arraystretch{1.25}
        \arrayrulecolor{numpexgray}
        {
            \fontsize{9}{11}\selectfont
            \begin{tabular}{!{\color{numpexgray}\vrule}p{.25\linewidth}!{\color{numpexgray}\vrule}p{.6885\linewidth}!{\color{numpexgray}\vrule}}

                \rowcolor{numpexgray}{\rule{0pt}{2.5ex}\color{white}\bf Bottlenecks}
                 & {\rule{0pt}{2.5ex}\color{white}\bf Short Description } \\

                \rowcolor{white}
                B10 - Scientific Productivity
                 & At the moment, each example needs to be run manually.
                The roadmap includes a way to automatically
                run relevant examples, based on input data.
                Future developments will include continuous benchmarking,
                in the form of a CI/CD pipeline.
                Some unit tests are already available,
                but their generalization is part of the roadmap.          \\
                \rowcolor{numpexlightergray}
                B11 - Reproducibility and Replicability of Computation
                 & At the moment, input data is hard-coded in examples.
                The roadmap includes a way to manage input data
                (e.g. in \texttt{json} files)
                and ensure reproducibility.                               \\
                \rowcolor{white}
                B6 - Data Management
                 & Data is saved locally, but not managed.
                The roadmap includes a data management system,
                with versioning and metadata.                             \\
                \rowcolor{numpexlightergray}
                B7 - Exascale Algorithms
                 & The roadmap includes multi-GPU support
                and performance optimization.                             \\
            \end{tabular}
        }
    }
    \caption{WP2: Scimba plan with Respect to Relevant Bottlenecks}
    \label{tab:WP2:Scimba:bottlenecks}
\end{table}
